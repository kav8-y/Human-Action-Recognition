# -*- coding: utf-8 -*-
"""Human Action Recognition (HAR) - CNN

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/#fileId=https%3A//storage.googleapis.com/kaggle-colab-exported-notebooks/human-action-recognition-har-cnn-0c45ad37-cbb8-4eb1-aee7-908d087ee1b8.ipynb%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com/20250312/auto/storage/goog4_request%26X-Goog-Date%3D20250312T150027Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D1a3de812cba97a45c127eb24809f4dd9dac66d8b3c08d497bbcf2b4594bbdbfa2d64511749498025704a7a8e8eb4b96213a195bb855d254478938584f541b02132f4901713be70a0dcf688be787d64b0c06a98def2a14d004c5e85fc0f4e92be55ee83e13716ab1f4f1a9003e4f791dd283a042d88f6814c02fcba9bfb0ace033d3ef32cdb1172429b2c521948a67366bf01b0aad489c231a14c29c8e06bb196f028c2ff76ef6deb8e81b1d258e65d9f745f27b2e55534bc0f7abb526c80c307dcf155acd8d7238d07904ba3fc2e74432b1be1c8876aec35293acb10fcc8505f3c13f2404cdc457a5f6fca366f578ab0603a93e7eb6c6ff3e100368e00cc210b
"""

# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,
# THEN FEEL FREE TO DELETE THIS CELL.
# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON
# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR
# NOTEBOOK.
import kagglehub
meetnagadia_human_action_recognition_har_dataset_path = kagglehub.dataset_download('meetnagadia/human-action-recognition-har-dataset')

print('Data source import complete.')

import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
import tensorflow as tf
from tensorflow.keras.preprocessing import image_dataset_from_directory
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.callbacks import EarlyStopping

# Load dataset paths
train_path = "/kaggle/input/human-action-recognition-har-dataset/Human Action Recognition/train"
test_path = "/kaggle/input/human-action-recognition-har-dataset/Human Action Recognition/test"
train_csv_path = "/kaggle/input/human-action-recognition-har-dataset/Human Action Recognition/Training_set.csv"
test_csv_path = "/kaggle/input/human-action-recognition-har-dataset/Human Action Recognition/Testing_set.csv"

# Load dataset paths
train_path = os.path.join(meetnagadia_human_action_recognition_har_dataset_path, "Human Action Recognition/train")
test_path = os.path.join(meetnagadia_human_action_recognition_har_dataset_path, "Human Action Recognition/test")
train_csv_path = os.path.join(meetnagadia_human_action_recognition_har_dataset_path, "Human Action Recognition/Training_set.csv")
test_csv_path = os.path.join(meetnagadia_human_action_recognition_har_dataset_path, "Human Action Recognition/Testing_set.csv")

# Load CSV files
train_df = pd.read_csv(train_csv_path)
test_df = pd.read_csv(test_csv_path)

# Store the original categories
categories = train_df['label'].astype('category').cat.categories

# Distribution of classes in training set
fig = px.histogram(train_df, x='label', title='Distribution of Classes in Training Set')
fig.show()

# Images from each class
fig, axes = plt.subplots(3, 5, figsize=(20, 10))
axes = axes.flatten()
for idx, class_name in enumerate(train_df['label'].unique()):
    class_images = train_df[train_df['label'] == class_name]['filename'].values
    img = plt.imread(os.path.join(train_path, class_images[0]))
    axes[idx].imshow(img)
    axes[idx].set_title(class_name)
    axes[idx].axis('off')
plt.tight_layout()
plt.show()

# Data Preprocessing
train_df['label'] = train_df['label'].astype('category')
train_df['label'] = train_df['label'].cat.codes
train_df['filepath'] = train_df['filename'].apply(lambda x: os.path.join(train_path, x))

# Split training and validation set
train_set, val_set = train_test_split(train_df, test_size=0.2, stratify=train_df['label'], random_state=42)

def load_image(filepath, label):
    image = tf.io.read_file(filepath)
    image = tf.image.decode_jpeg(image, channels=3)
    image = tf.image.resize(image, [128, 128])
    image = image / 255.0
    return image, label

# Create TensorFlow datasets
train_dataset = tf.data.Dataset.from_tensor_slices((train_set['filepath'].values, train_set['label'].values))
train_dataset = train_dataset.map(load_image).batch(32).shuffle(buffer_size=len(train_set))

val_dataset = tf.data.Dataset.from_tensor_slices((val_set['filepath'].values, val_set['label'].values))
val_dataset = val_dataset.map(load_image).batch(32)

# Model Building
model = Sequential([
    Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),
    MaxPooling2D((2, 2)),
    Conv2D(64, (3, 3), activation='relu'),
    MaxPooling2D((2, 2)),
    Conv2D(128, (3, 3), activation='relu'),
    MaxPooling2D((2, 2)),
    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.5),
    Dense(15, activation='softmax')
])

model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

import tensorflow as tf

# Early Stopping to stop training when validation loss stops improving
early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)

# Train the model with Early Stopping
history = model.fit(train_dataset,validation_data=val_dataset,epochs=30, callbacks=[early_stopping])

# Plot Training and Validation Accuracy
fig = go.Figure()
fig.add_trace(go.Scatter(x=np.arange(len(history.history['accuracy'])), y=history.history['accuracy'], mode='lines', name='Training Accuracy'))
fig.add_trace(go.Scatter(x=np.arange(len(history.history['val_accuracy'])), y=history.history['val_accuracy'], mode='lines', name='Validation Accuracy'))
fig.update_layout(title='Model Accuracy', xaxis_title='Epoch', yaxis_title='Accuracy')
fig.show()

# Plot Training and Validation Loss
fig = go.Figure()
fig.add_trace(go.Scatter(x=np.arange(len(history.history['loss'])), y=history.history['loss'], mode='lines', name='Training Loss'))
fig.add_trace(go.Scatter(x=np.arange(len(history.history['val_loss'])), y=history.history['val_loss'], mode='lines', name='Validation Loss'))
fig.update_layout(title='Model Loss', xaxis_title='Epoch', yaxis_title='Loss')
fig.show()

# Get true labels from the validation dataset
val_labels = np.concatenate([y for x, y in val_dataset], axis=0)

# Get model predictions for the validation dataset
val_predictions = np.argmax(model.predict(val_dataset), axis=-1)

# Confusion Matrix
conf_matrix = confusion_matrix(val_labels, val_predictions)
fig = px.imshow(conf_matrix, text_auto=True, title='Confusion Matrix')
fig.show()

# Save model
model.save('/kaggle/output/human_action_recognition_model.h5')

# Prepare test data
test_df['filepath'] = test_df['filename'].apply(lambda x: os.path.join(test_path, x))

test_dataset = tf.data.Dataset.from_tensor_slices(test_df['filepath'].values)
test_dataset = test_dataset.map(lambda x: (tf.image.resize(tf.image.decode_jpeg(tf.io.read_file(x), channels=3), [128, 128]) / 255.0)).batch(32)

# Predict on test set
test_predictions = np.argmax(model.predict(test_dataset), axis=-1)
test_df['label'] = test_predictions

# Map label codes back to class names
label_map = {i: label for i, label in enumerate(categories)}
test_df['label'] = test_df['label'].map(label_map)

# Prepare submission
submission = test_df[['filename', 'label']]
submission.to_csv('/kaggle/output/submission.csv', index=False)

# Show 10 images with actual and predicted labels from validation set
fig, axes = plt.subplots(2, 5, figsize=(20, 10))
axes = axes.flatten()
sampled_val_set = val_set.sample(10, random_state=42)
for i, (index, row) in enumerate(sampled_val_set.iterrows()):
    img = plt.imread(row['filepath'])
    actual_label = categories[row['label']]
    predicted_label = categories[val_predictions[val_set.index.get_loc(index)]]
    axes[i].imshow(img)
    axes[i].set_title(f"Actual: {actual_label}\nPredicted: {predicted_label}")
    axes[i].axis('off')
plt.tight_layout()
plt.show()